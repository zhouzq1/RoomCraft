<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>RoomCraft</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">RoomCraft: 3D Indoor Scene Generation with Adaptive Layout Optimization</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="mailto:zhoumengqi2022@ia.ac.cn">Mengqi Zhou</a><sup>1,3,4,5*</sup>,</span>
            <span class="author-block">
              <a href="mailto:wangxiping2024@ia.ac.cn@ia.ac.cn">Xiping Wang</a><sup>1,3,4,5*</sup>,</span>
            <span class="author-block">
              <a href="mailto:yuxiwang93@gmail.com">Yuxi Wang</a><sup>2‡</sup>,</span>
            <span class="author-block">
              <a href="mailto:zhaoxiang.zhang@ia.ac.cn">Zhaoxiang Zhang</a><sup>1,2,3,4,5‡</sup>,</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Chinese Academy of Sciences (UCAS),</span>
            <span class="author-block"><sup>2</sup>Centre for Artificial Intelligence and Robotics (CAIR),</span>
            <span class="author-block"><sup>3</sup>Institute of Automation, Chinese Academy of Sciences (CASIA),</span>
            <span class="author-block"><sup>4</sup>New Laboratory of Pattern Recognition (NLPR),</span>
            <span class="author-block"><sup>5</sup>State Key Laboratory of Multimodal Artificial Intelligence Systems (MAIS),</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">*Equal contribution, ‡Corresponding author</span>
          </div>
          
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2403.15698"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2403.15698"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/zhouzq1/RoomCraft"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./video/bed.mkv"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./video/din.mkv"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./video/kit.mkv"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./video/liv.mkv"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Generating realistic 3D indoor scenes is a fundamental challenge in the field of Artificial General Intelligence (AGI), as it requires balancing geometric consistency, physical interactivity, and visual realism. While implicit generation methods, including diffusion-based and LLM-based approaches, have made promising strides, they often struggle with issues such as repetitive elements and unrealistic layouts due to a lack of global context.
            To address these issues, we propose RoomCraft, an explicit generation method that converts the provided real images, sketches, or text descriptions into realistic 3D indoor scenes. RoomCraft integrates a multi-stage interactive generation pipeline that extracts high-level scene information from user inputs and organizes it into a structured format. Then it constructs a spatial relationship network to represent furniture positions and generates a task list using a heuristic-based search to ensure layout coherence. Additionally, we introduce an adaptive layout optimization algorithm that balances spatial functionality and aesthetic appeal, dynamically adjusting to resolve conflicts and changes in layout. We demonstrate the effectiveness of RoomCraft through extensive experiments, showing that it outperforms existing methods in generating realistic, semantically coherent, and visually appealing room layouts.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 mt-5">The proposed SceneX can create large-scale 3D natural scenes or unbounded cities automatically according to user instructions.</h2>
        <img src="./image/exp_00.jpg" alt="The proposed SceneX can create large-scale 3D natural scenes or unbounded cities automatically according to user instructions. The generated models are characterized by delicate geometric structures, realistic material textures, and natural lighting, allowing for seamless deployment in the industrial pipeline." height="100%">
        <p class="content has-text-justified">
          The generated models are characterized by delicate geometric structures, realistic material textures, and natural lighting, allowing for seamless deployment in the industrial pipeline.
        </p>
      </div>
    </div>
    <!--/ Image section 1. -->
    <!-- Image section 2. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 mt-5">The PCG Planner framework</h2>
        <img src="./image/fig1_00.jpg" alt="The proposed SceneX can create large-scale 3D natural scenes or unbounded cities automatically according to user instructions. The generated models are characterized by delicate geometric structures, realistic material textures, and natural lighting, allowing for seamless deployment in the industrial pipeline." height="100%">
        <p class="content has-text-justified">
          The PCG Planner framework comprises three essential components: the task planner, asset retrieval, and action execution. This framework empowers LLMs with the capabilities for task planning in complex scenarios, utilizing multiple API actions, and facilitating large-scale scene generation.
        </p>
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 mt-5">The proposed SceneX can create large-scale 3D natural scenes or unbounded cities automatically according to user instructions.</h2>
        <img src="./image/pipeline (1)_00.jpg" alt="The proposed SceneX can create large-scale 3D natural scenes or unbounded cities automatically according to user instructions. The generated models are characterized by delicate geometric structures, realistic material textures, and natural lighting, allowing for seamless deployment in the industrial pipeline." height="100%">
        <p class="content has-text-justified">
          The generated models are characterized by delicate geometric structures, realistic material textures, and natural lighting, allowing for seamless deployment in the industrial pipeline.
        </p>
      </div>
    </div>
    <!--/ Image section 1. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 mt-5">The proposed SceneX can create large-scale 3D natural scenes or unbounded cities automatically according to user instructions.</h2>
        <img src="./image/progressive(1)_00.jpg" alt="The progressive layout generation results using the given instructions." height="100%">
        <p class="content has-text-justified">
          Illustration results for our adaptive layout generation. Taking the first row as an example, our method effectively constructs a layout by progressively adding furniture according to the user input, such as a bed, side table, armchair, and desk, while intuitively maintaining spatial relationships to avoid overcrowding.
        </p>
      </div>
    </div>
    <!--/ Image section 1. -->
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">Citation</h2>
    <pre><code>@article{,
  author = {Mengqi Zhou and Jun Hou and Chuanchen Luo and Yuxi Wang and Zhaoxiang Zhang and Junran Peng},
  title  = {SceneX: Procedural Controllable Large-scale Scene Generation via Large-language Models},
  journal = {arXiv preprint arXiv:2403.15698},
  year = {2024},
}</code></pre>
  </div>
</section>


</body>
</html>
